aliases:
  - &filter-only-prs-dependabot
    branches:
      only:
        - /^pull\/.+$/
        - /^dependabot\/.+$/
  - &filter-only-auto-canary
    branches:
      only:
        - auto
        - canary
  - &working_directory /opt/git/diem
  - &image libra/build_environment:circleci-2

version: 2.1

orbs:
  slack: circleci/slack@3.3.0
  aws-ecr: circleci/aws-ecr@6.12.2
  aws-cli: circleci/aws-cli@0.1.13

executors:
  docker-xlarge-executor:
    docker:
      - image: *image
    resource_class: xlarge
  docker-medium-executor:
    docker:
      - image: *image
    resource_class: medium
  vm-xlarge-caching-executor:
    machine:
      docker_layer_caching: true
      image: ubuntu-1604:202004-01
    resource_class: xlarge
  vm-xlarge-executor:
    machine:
      docker_layer_caching: false
      image: ubuntu-1604:202004-01
    resource_class: xlarge
  vm-large-executor:
    machine:
      docker_layer_caching: false
      image: ubuntu-1604:202004-01
    resource_class: large
  vm-medium-executor:
    machine:
      docker_layer_caching: false
      image: ubuntu-1604:202004-01
    resource_class: medium

commands:
  install_deps_on_vm_executor:
    description: Install build dependencies on vm executor
    steps:
      - run:
          name: Update Debian package source
          command: |
            sudo apt-get update
      - run:
          name: Install Dependencies
          command: |
            sudo apt-get install -y cmake curl clang llvm
      - run:
          name: Install rustup and cargo if not found in container
          command: |
            if ! [ -x "$(command -v cargo)" ] || ! [ -x "$(command -v rustup)" ]; then \
              curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs \
              | sh -s -- -y --default-toolchain $(cat rust-toolchain); \
              echo 'export PATH=$PATH:~/.cargo/bin' >> $BASH_ENV; \
            fi
      - run:
          name: Install nightly version of rust toolchain for cargo with v2 feature resolver
          command: rustup install $(cat cargo-toolchain)
      - run:
          name: Install specific version of rust toolchain
          command: rustup install $(cat rust-toolchain)
      - run:
          name: Version Information
          command: rustc --version; cargo --version; rustup --version
      - run:
          name: Install Rust linters
          command: |
            rustup component add clippy rustfmt --toolchain $(cat rust-toolchain)
  print_versions:
    description: Version Info
    steps:
      - run:
          name: Version Info
          command: rustup --version ; rustc --version
  shell_setup:
    description: Shell Setup
    steps:
      - run:
          name: Setup Env
          command: |
            mkdir -p /opt/cargo/
            export CARGO_HOME=/opt/cargo
            echo 'export CARGO_HOME=/opt/cargo' >> $BASH_ENV
            echo 'export TAG=0.1.${CIRCLE_BUILD_NUM}' >> $BASH_ENV
            echo 'export IMAGE_NAME=myapp' >> $BASH_ENV
            echo 'export LIBRA_DUMP_LOGS=1' >> $BASH_ENV
            echo 'export CARGO_INCREMENTAL=0' >> $BASH_ENV
            echo 'export CI_TIMEOUT="timeout 70m"' >> $BASH_ENV
            export RUST_NIGHTLY=$(cat cargo-toolchain)
            echo 'export RUST_NIGHTLY='"$RUST_NIGHTLY" >> $BASH_ENV

            # Turn on the experimental feature resolver in cargo. See:
            # https://doc.rust-lang.org/nightly/cargo/reference/unstable.html#features
            echo 'export CARGOFLAGS='$(cat cargo-flags) >> $BASH_ENV
            # Use nightly version of cargo to access the new feature resolver
            echo 'export CARGO='$(rustup which cargo --toolchain "$RUST_NIGHTLY") >> $BASH_ENV
            # Pin the version of RUSTC used for all invocations of cargo
            echo 'export RUSTUP_TOOLCHAIN="$(cat rust-toolchain)"' >> $BASH_ENV
  move_shell_setup:
    description: Shell Setup
    steps:
      - run:
          name: Setup Env
          command: |
            # Configure Move prover tools
            echo 'export Z3_EXE="$HOME/bin/z3"' >> $BASH_ENV
            echo 'export DOTNET_ROOT="$HOME/.dotnet"' >> $BASH_ENV
            echo 'export BOOGIE_EXE="$HOME/.dotnet/tools/boogie"' >> $BASH_ENV
  fail_if_debian_buster_docker_base_images_are_not_tagged_with_sha256:
    steps:
      - run:
          name: Verify all debian buster images have sha256s.
          when: always
          command: |
            set -e
            # We are using debian for our base images.   Get all debain tags in FROM lines, strip the "AS .*" part
            ALL_BUSTER_TAGS=$(grep --include=\*Dockerfile -r '.' -e 'FROM debian:' | sed 's/[ ]*[a|A][s|S] .*$//g')
            while IFS= read -r line ; do
              # if the line does not end in a git tag, echo the line and mark the build as bad.
              if [[ ! $line =~ '@sha256:' ]]; then
                echo "Give this docker image FROM line a sha256 in it's tag.   Failing the build."
                echo "$line";
                SHOULD_FAIL="true";
              else
                echo checked "$line"
              fi
            done \<<< "$ALL_BUSTER_TAGS"
            if [[ "$SHOULD_FAIL" == "true" ]]; then
              exit 1
            fi
  halt_if_no_relevant_files_changed_since_last_evaluation:
    description: |
      halts the job if no relevant files have changed.
      This is determined by using a cached file containing the last git revision the build evaluated.
      Branch is part of the cache key name, following the parameter, cache_key_part.
      The build did not necessarily need to proceed on the last evaluation if no relevant files had changed,
      and cache keys will still be updated on each evaluation before halting.
      If this build is the result of a pull request, bors auto run, the pr information is prefered over the $previoushead,
      and compared to the merge base of the target branch.
      Relevant files are looked up from an existing file on the execution env, passed in as a parameter, the
      file of relevant git files.
    parameters:
      cache_key_part:
        description: part of the cache key name used by circle in the job.
        type: string
      file_of_relevant_git_files:
        description: file to be provided to these steps, of relevant git files.
        type: string
    steps:
      - restore_cache:
          name: restore latch cache file.
          key: last-githash-{{ .Environment.CIRCLE_BRANCH }}-<< parameters.cache_key_part >>
      - run:
          name: Detect if relevant files have changed.
          command: |
            touch /home/circleci/lastbuildgithash
            previoushead=$(cat /home/circleci/lastbuildgithash)
            output=$(.circleci/get_pr_info.sh -g $previoushead -b)
            echo Output: "$output"
            eval "$output"
            echo Changed: $(cat "$CHANGED_FILE_OUTPUTFILE")
            if [[ -n "$BASE_GITHASH" ]] && [ $(join "$CHANGED_FILE_OUTPUTFILE" << parameters.file_of_relevant_git_files >> | wc -l) == 0 ]; then
              echo no relevant files have changed will halt
              echo "halt" > /tmp/should_halt
            else
              echo Relevant files have changed - or could not detect changes, building.
              echo "continue" > /tmp/should_halt
            fi
            git rev-parse HEAD > /home/circleci/lastbuildgithash
      - save_cache:
          name: store updated cache file.
          key: last-githash-{{ .Environment.CIRCLE_BRANCH }}-<< parameters.cache_key_part >>-{{ epoch }}
          paths:
            - /home/circleci/lastbuildgithash
      - run:
          name: halt if no changes
          command: |
            if [[ "$(cat /tmp/should_halt)" == "halt" ]]; then
              echo halting job.
              circleci step halt
            fi

  save_cargo_package_cache:
    description: Save cargo package cache for subsequent jobs
    steps:
      - save_cache:
          name: Save cargo package cache
          key: cargo-package-sccache-new-{{ checksum "Cargo.lock" }}
          # paths are relative to /home/circleci/project/
          paths:
            - "/opt/cargo/git"
            - "/opt/cargo/registry"
            - "/opt/cargo/.package-cache"
  restore_cargo_package_cache:
    description: Restore Cargo package cache from prev job
    steps:
      - run:
          name: Deal with non-relative cache locations.
          command: |
            sudo mkdir -p /usr/local/cargo/
            sudo chmod 777 /usr/local/cargo/
      - restore_cache:
          name: Restore cargo package cache
          key: cargo-package-sccache-new-{{ checksum "Cargo.lock" }}
      - run:
          name: Check cargo package cache
          command: |
            ls -all /opt/cargo
            du -ssh /opt/cargo
  save_breaking_change_rev:
    description: Save the breaking change rev since last testnet update.
    steps:
      - save_cache:
          name: Save breaking change rev
          key: testnet-v1-{{ checksum "testnet_rev" }}
          # paths are relative to /home/circleci/project/
          paths:
            - breaking_change_rev
          when: on_fail
  restore_breaking_change_rev:
    description: Restore the breaking change rev since last testnet update
    steps:
      - restore_cache:
          name: Restore breaking change rev
          key: testnet-v1-{{ checksum "testnet_rev" }}
  send_message:
    description: Send message to the specified webhook, if no webhook is set simply return.
    parameters:
      payload_file:
        description: File containing the message payload
        type: string
        default: ""
      build_url:
        description: This build's URL in Circle
        type: string
        default: "${CIRCLE_BUILD_URL}"
      webhook:
        description: Webhook for the message
        type: string
        default: ""
    steps:
      - run:
          name: Send job status
          command: |
            if [ -e <<parameters.payload_file>> ]; then
              jq -n \
                --arg msg "$(cat <<parameters.payload_file>>)" \
                --arg url "<<parameters.build_url>>" \
                '{
                  attachments: [
                    {
                      text: $msg,
                      actions: [
                        {
                          "type": "button",
                          "text": "Visit Job",
                          "url": $url
                        }
                      ],
                    }
                  ]
                }' > /tmp/payload
              cat /tmp/payload
              if [ <<parameters.webhook>> ]; then
                curl -X POST -H 'Content-type: application/json' -d @/tmp/payload \
                <<parameters.webhook>>
              else
                echo "Not sending messages as no webhook url is set."
                echo "Chances are you are not building on master, or circle is misconfigured."
                echo "webhook is empty"
                exit 0
              fi
            fi
          when: always
  build_setup:
    steps:
      - run:
          command: |
            sudo mkdir -p /opt/cargo/
            sudo chown circleci /opt/cargo/
            sudo mkdir -p /opt/git/
            sudo chown circleci /opt/git/
          working_directory: ~/project
      - checkout:
          path: *working_directory
      - print_versions
      - run:
          name: update tooling if needed.
          command: scripts/dev_setup.sh -t -o -b -p -y
      - shell_setup
      - move_shell_setup
  vm_build_setup:
    steps:
      - run:
          command: |
            sudo mkdir -p /opt/cargo/
            sudo chown circleci /opt/cargo/
            sudo mkdir -p /opt/git/
            sudo chown circleci /opt/git/
          working_directory: ~/project
      - checkout:
          path: *working_directory
      - install_deps_on_vm_executor
      - run:
          name: install move tools, modify shell
          command: |
            scripts/dev_setup.sh -b -p -y
            source "${HOME}"/.profile
          working_directory: *working_directory
      - shell_setup
      - move_shell_setup
      - print_versions
  build_teardown:
    steps:
      - run:
          name: Check for changed and untracked files
          command: ./scripts/changed-files.sh
  setup_docker_signing:
    steps:
      - run:
          name: Setup docker login and signing if creds are available.
          command: |
            set -x
            if [[ -z "$DOCKERHUB_PASSWORD" ]]; then
              echo Lacking credentials for docker hub, not signing in.
            else
              # echo 'export DOCKER_CONTENT_TRUST=1' >> $BASH_ENV
              echo "$DOCKERHUB_PASSWORD" | docker login -u "$DOCKERHUB_USERNAME" --password-stdin
              export DOCKER_CONTENT_TRUST_REPOSITORY_PASSPHRASE=${DOCKERHUB_KEY_PASSWORD}
              echo 'export DOCKER_CONTENT_TRUST_REPOSITORY_PASSPHRASE=${DOCKERHUB_KEY_PASSWORD}' >> $BASH_ENV
              mkdir -p ~/.docker/trust/private/
              echo ${DOCKERHUB_KEY_MATERIAL} | base64 -d > ~/.docker/trust/private/${DOCKERHUB_KEY_NAME}.key
              chmod 600 ~/.docker/trust/private/${DOCKERHUB_KEY_NAME}.key
              docker trust key load ~/.docker/trust/private/${DOCKERHUB_KEY_NAME}.key --name "$DOCKERHUB_USERNAME"
              echo Docker hub is logged in, and signing is available.
            fi
  setup_aws:
    description: Set up access to AWS
    steps:
      - run:
          name: Compose AWS Env Variables
          command: |
            echo 'export AWS_ECR_ACCOUNT_URL="${AWS_ECR_ACCOUNT_NUM}.dkr.ecr.${AWS_REGION}.amazonaws.com"' >> $BASH_ENV
      - aws-cli/configure:
          aws-access-key-id: AWS_ACCESS_KEY_ID
          aws-secret-access-key: AWS_SECRET_ACCESS_KEY
          aws-region: AWS_REGION
      - aws-ecr/ecr-login
jobs:
  prefetch-crates:
    working_directory: *working_directory
    executor: docker-medium-executor
    description: Prefetch cargo crates for subsequent jobs.
    steps:
      - build_setup
      - run:
          name: Git Hooks and Checks
          command: ./scripts/git-checks.sh
      - restore_cargo_package_cache
      - run:
          name: Fetch workspace dependencies over network
          command: |
            echo $CARGO $CARGOFLAGS fetch
            RUST_BACKTRACE=1 $CARGO $CARGOFLAGS fetch
      - save_cargo_package_cache
  lint:
    working_directory: *working_directory
    executor: docker-xlarge-executor
    description: Run Rust linting tools.
    steps:
      - build_setup
      - restore_cargo_package_cache
      - run:
          name: cargo lint
          command: cargo x lint
      - run:
          name: cargo clippy
          command: cargo xclippy --workspace --all-targets
      - run:
          name: cargo clippy tcb
          command: cargo xclippy --members lec --members lsr --members key-manager
      - run:
          name: cargo fmt
          command: cargo xfmt --check
      - run:
          name: shell lints
          command: |
            shellcheck scripts/dev_setup.sh && \
            shellcheck scripts/dockerhub_prune.sh && \
            shellcheck .circleci/get_pr_info.sh && \
            shellcheck docker/build_push.sh && \
            shellcheck docker/dockerhub_to_novi_ecr.sh
      - run:
          name: docker lints
          command: |
            hadolint docker/ci/circleci/Dockerfile && \
            hadolint docker/ci/arch/Dockerfile && \
            hadolint docker/ci/alpine/Dockerfile && \
            hadolint docker/ci/centos/Dockerfile
  build-dev:
    working_directory: *working_directory
    executor: docker-xlarge-executor
    description: Development Build
    steps:
      - build_setup
      - restore_cargo_package_cache
      - run:
          command: RUST_BACKTRACE=1 cargo xcheck -j 16 --members production
      - run:
          command: RUST_BACKTRACE=1 cargo xcheck -j 8 --workspace --all-targets
      - run:
          command: |
            rustup target add powerpc-unknown-linux-gnu
            RUST_BACKTRACE=1 cargo xcheck -j 8 -p transaction-builder -p move-vm-types --target powerpc-unknown-linux-gnu
      - build_teardown
  run-e2e-test:
    working_directory: *working_directory
    executor: docker-xlarge-executor
    parallelism: 2
    description: Run E2E tests in parallel. Each container runs a subset of
      test targets.
    environment:
      E2E_RETRIES: 3
      FLAKY_TESTS_FILE: "/tmp/flaky_tests"
      MESSAGE_PAYLOAD_FILE: "/tmp/message_payload"
    steps:
      - build_setup
      - restore_cargo_package_cache
      - run:
          name: Determine test targets for this container.
          # NOTE Currently the tests are distributed by name order. Once test
          # metadata is enabled, the tests can be distributed by run time to
          # speed up this job.
          command: |
            RUST_BACKTRACE=1 cargo x test --package smoke-test -- --list | \
              grep "::" | sed 's/: .*$//' > e2e_tests
            cat e2e_tests
            echo -e "Found $(wc -l e2e_tests) tests."
            cat e2e_tests | circleci tests split > /tmp/tests_to_run
            echo -e "This runner will run these tests\n$(cat /tmp/tests_to_run)"
      - run:
          name: Run E2E tests
          # NOTE
          # +e to disable exit immediately when test timeout in the retry loop
          command: |
            set +e
            num_fails=0
            failed_tests=
            for target in $(cat /tmp/tests_to_run) ; do
              retry=0
              status=1
              while [[ $status != 0 && $retry < ${E2E_RETRIES} ]]; do
                RUST_BACKTRACE=full timeout --kill-after=370 --preserve-status 360 \
                  cargo x test --package smoke-test -- $target --test-threads 1 --exact --nocapture
                status=$?
                retry=$((retry + 1))
                if [[ $status != 0 ]] ; then
                   echo Failed to execute $target, $retry times
                fi
                sleep 10
              done
              if [[ $status != 0 ]] ; then
                num_fails=$((num_fails + 1))
                echo failed to execute $target
                failed_tests="${target}\n${failed_tests}"
              elif [[ $retry > 1 ]]; then
                echo "$target passed after $retry tries" >> ${FLAKY_TESTS_FILE}
              fi
            done
            if [ -e ${FLAKY_TESTS_FILE} ]; then
              msg="Found flaky tests\n$(cat ${FLAKY_TESTS_FILE})"
              echo -e $msg
              echo -e $msg > ${MESSAGE_PAYLOAD_FILE}
            fi
            if [[ $num_fails != 0 ]]; then
              echo -e "$num_fails test(s) failed:\n${failed_tests}"
            fi
            exit $num_fails
      - send_message:
          payload_file: "${MESSAGE_PAYLOAD_FILE}"
          build_url: "https://app.circleci.com/pipelines/github/${CIRCLE_PROJECT_USERNAME}/${CIRCLE_PROJECT_REPONAME}/<<pipeline.number>>/workflows/${CIRCLE_WORKFLOW_ID}/jobs/${CIRCLE_BUILD_NUM}/parallel-runs/${CIRCLE_NODE_INDEX}?filterBy=ALL"
          webhook: "${WEBHOOK_FLAKY_TESTS}"
  run-unit-test:
    working_directory: *working_directory
    executor: vm-xlarge-executor
    description: Run affected unit tests, excluding E2E and flaky tests that are
      explicitly ignored.
    steps:
      - vm_build_setup
      - restore_cargo_package_cache
      - run:
          name: Run affected unit tests
          command: |
            eval $(.circleci/get_pr_info.sh -b)
            RUST_BACKTRACE=1 $CI_TIMEOUT cargo x test --jobs 8 --unit --changed-since "origin/$TARGET_BRANCH"
  run-crypto-unit-test:
    working_directory: *working_directory
    executor: docker-medium-executor
    description: Run crypto unit tests without formally verified crypto, to insulate against a curve25519 "default" backend regression
    steps:
      - build_setup
      - restore_cargo_package_cache
      - run:
          name: Run crypto unit tests
          command: |
            cd crypto/crypto && \
            RUST_BACKTRACE=1 $CARGO $CARGOFLAGS test \
              --features='vanilla-u64' \
              --no-default-features && \
            RUST_BACKTRACE=1 $CARGO $CARGOFLAGS test \
              --features='vanilla-u32' \
              --no-default-features
  build-benchmark:
    working_directory: *working_directory
    executor: vm-xlarge-executor
    description: Compile (but don't run) the benchmarks, to insulate against bit rot
    steps:
      - vm_build_setup
      - restore_cargo_package_cache
      - run:
          name: Build benchmark targets without running
          command: |
            RUST_BACKTRACE=1 cargo x bench \
              --no-run
  run-flaky-unit-test:
    working_directory: *working_directory
    executor: test-executor
    description: Run a list of known flaky tests.
    steps:
      - build_setup
      - restore_cargo_package_cache
      - run:
          name: Run flaky tests
          command: |
            RUST_BACKTRACE=1 $CI_TIMEOUT \
            ./scripts/run_quarantined.sh -c <your package here> -r 3 -f
  audit:
    working_directory: *working_directory
    executor: docker-medium-executor
    steps:
      - build_setup
      - restore_cargo_package_cache
      - run:
          name: Install Cargo Audit
          command: |
            cargo install --force cargo-audit
      - run:
          # NOTE ignored advisory rules
          # RUSTSEC-2018-0015 - term
          # RUSTSEC-2019-0031 - spin
          name: Audit crates
          command: |
            $CARGO $CARGOFLAGS audit --deny-warnings \
              --ignore RUSTSEC-2018-0015 \
              --ignore RUSTSEC-2019-0031 \
              --ignore RUSTSEC-2020-0016
      - build_teardown
  lint-docker:
    working_directory: *working_directory
    executor: docker-medium-executor
    description: Lint changed Dockerfiles
    steps:
      - run:
          command: |
            sudo mkdir -p /opt/cargo/
            sudo chown circleci /opt/cargo/
            sudo mkdir -p /opt/git/
            sudo chown circleci /opt/git/
          working_directory: ~/project
      - checkout:
          path: *working_directory
      - run:
          name: Lint DockerFile changes
          command: |
            eval $(.circleci/get_pr_info.sh -b)
            if  [[ -n "$BASE_GITHASH" ]] && [[ -n "$CHANGED_FILE_OUTPUTFILE" ]]; then
              CHANGED_DOCKER_FILE_LIST=$( (grep Dockerfile $CHANGED_FILE_OUTPUTFILE || true) | tr '\n' ' ' )
              if [[ -n "$CHANGED_DOCKER_FILE_LIST" ]]; then
                hadolint -c .lintrules/hadolint.yaml "$CHANGED_DOCKER_FILE_LIST" || true
              fi
            fi
      - fail_if_debian_buster_docker_base_images_are_not_tagged_with_sha256
  check-breaking-change:
    working_directory: *working_directory
    executor: docker-medium-executor
    description: Detect breaking change in CLI
    environment:
      # NOTE The  built-in save_cache and restore_cache cmds dont accept cache
      # path or cache key defined via env var on the fly. As a result, if you
      # change BREAKING_CHANGE_REV_FILE or TESTNET_REV_FILE, make sure to change
      # save_breaking_change_rev and restore_breaking_change_rev accordingly.
      BREAKING_CHANGE_REV_FILE: "breaking_change_rev"
      TESTNET_REV_FILE: "testnet_rev"
    steps:
      - build_setup
      - run:
          name: Prepare cache key for breaking change rev lookup
          # NOTE save_cache and restore_cache dont take cache key defined via
          # env var on the fly. So we are going to store the testnet rev in a
          # file and use its checksum as cache key.
          command: |
            echo 'export GIT_REV=$(git rev-parse HEAD)' >> $BASH_ENV
            git rev-parse origin/testnet > ${TESTNET_REV_FILE}
      - restore_breaking_change_rev
      - run:
          name: Check exiting breaking change rev
          command: |
            pwd
            if [ -f "${BREAKING_CHANGE_REV_FILE}" ]; then
              echo "master already has breaking change $(cat ${BREAKING_CHANGE_REV_FILE})"
              echo "Nothing to do. Halting CI..."
              circleci step halt
            else
              echo "No existing breacking change rev. Will continue CI."
            fi
      - restore_cargo_package_cache
      - run:
          name: Construct CLI cmds
          command: |
            echo "
              a c
              a m 0 10 LBR false
              q b 0
              a c
              a m 1 11 LBR false
              q b 1
              t 0 1 1 LBR
              q b 0
              q b 1
              quit
            " > /tmp/cli
      - run:
          name: Connect to testnet
          # NOTE +e to disable exit immediately on failure
          command: |
            set +e
            ./scripts/cli/start_cli_testnet.sh < /tmp/cli
            status=$?
            if [[ $status != 0 ]] ; then
              git rev-parse HEAD > ${BREAKING_CHANGE_REV_FILE}
              echo "Will save breaking change rev $(cat ${BREAKING_CHANGE_REV_FILE})"
            fi
            exit $status
      - save_breaking_change_rev
      - slack/status:
          fail_only: true
          webhook: "${WEBHOOK_BREAKING_CHANGE}"
          failure_message: ":red_circle: <@channel> breaking change in *${GIT_REV}*"
  ######################################################################################################
  # Building docker ci base image if relevant files have changed                                       #
  # Only if "release" parameter is true, will docker images be pushed to Dockerhub and Novi AWS ECR    #
  # Dockerhub Image prunning also occurs after a push removing old Dockerhub Images                    #
  # The "target-image" parameter determines which docker image in to build:                            #
  #   libra/docker/ci/< target-image >/Dockerfile                                                      #
  # Only circlci images need to be released, others general should not be and only exist to test the   #
  # dev_setup.sh script                                                                                #
  ######################################################################################################
  docker-ci-build:
    working_directory: *working_directory
    executor: vm-large-executor
    parameters:
      target-image:
        description: |
          The "target-image" parameter determines which docker image in to build:
          ex: libra/docker/ci/< target-image >/Dockerfile
        type: enum
        enum: ["circleci", "alpine", "arch", "centos"]
      release:
        description: Should we push to dockerhub/novi aws ecr.
        type: boolean
        default: false
      version:
        description: |
          increment this number if you make a backwards breaking change in the dev_setup.sh
          You must also bump &image at the start of this file.
        type: integer
        default: 0
    steps:
      - run:
          command: |
            sudo mkdir -p /opt/cargo/
            sudo chown circleci /opt/cargo/
            sudo mkdir -p /opt/git/
            sudo chown circleci /opt/git/
          working_directory: ~/project
      - checkout:
          path: *working_directory
      - run:
          name: Define relevant files
          command: |
            echo "cargo-toolchain" >> /tmp/ci_docker_files
            echo "docker/ci/<< parameters.target-image >>/Dockerfile" >> /tmp/ci_docker_files
            echo "rust-toolchain" >> /tmp/ci_docker_files
            echo "scripts/dev_setup.sh -t" >> /tmp/ci_docker_files
      - halt_if_no_relevant_files_changed_since_last_evaluation:
          cache_key_part: "dockerbuild"
          file_of_relevant_git_files: "/tmp/ci_docker_files"
      - run:
          name: Build/test << parameters.target-image >>-<< parameters.version >> docker image file
          command: |
            docker build -f docker/ci/<< parameters.target-image >>/Dockerfile -t libra/build_environment:<< parameters.target-image >>-<< parameters.version >> .
      - when:
          condition: << parameters.release >>
          steps:
            - setup_docker_signing
            - run:
                name: push libra/build_environment:<< parameters.target-image >>-<< parameters.version >> docker image
                command: |
                  #signs the pushed image
                  docker push --disable-content-trust=false libra/build_environment:<< parameters.target-image >>-<< parameters.version >>

  docker-update-base-images:
    working_directory: *working_directory
    executor: vm-medium-executor
    steps:
      - run:
          command: |
            sudo mkdir -p /opt/cargo/
            sudo chown circleci /opt/cargo/
            sudo mkdir -p /opt/git/
            sudo chown circleci /opt/git/
          working_directory: ~/project
      - checkout:
          path: *working_directory
      - run:
          name: Define relevant files
          command: |
            grep --include=\*Dockerfile -r '.' -e 'FROM debian:' | sed 's/:.*//g' | sed 's/\.\///g' | sort | uniq > /tmp/ci_docker_files
      - halt_if_no_relevant_files_changed_since_last_evaluation:
          cache_key_part: docker_base_image
          file_of_relevant_git_files: /tmp/ci_docker_files
      - setup_aws
      - run:
          name: Push base images to ecr if needed for cluster test.
          command: |
            # We are using debian buster for our base images.   Get all debian tags in a unique sorted list.
            BUSTER_TAGS=`grep --include=\*Dockerfile -rh '.' -e 'FROM debian:' | sed 's/FROM debian://g' | sed 's/[ ]*[a|A][s|S] .*$//g' | sort | uniq`
            echo "$BUSTER_TAGS" | while IFS= read -r tag ; do
              docker pull debian:$tag
            done
            #login to docker aws ecr account
            aws ecr get-login-password --region ${AWS_REGION} | \
            docker login --username AWS --password-stdin "${AWS_ECR_ACCOUNT_URL}"
            #push all base docker images to aws.
            set -x
            echo "$BUSTER_TAGS" | while IFS= read -r tag ; do
              tag_no_sha=`echo $tag | sed 's/@.*//'`
              docker tag debian:$tag ${AWS_ECR_ACCOUNT_URL}/library/debian:${tag_no_sha}
              docker push ${AWS_ECR_ACCOUNT_URL}/library/debian:${tag_no_sha}
            done

  ######################################################################################################
  # Publish docker artifacts for prs targeting release branches built in "auto" by bors.               #
  # Disabled for now, until bors pipeline more configurable.                                           #
  ######################################################################################################
  docker-pre-publish:
    working_directory: *working_directory
    executor: vm-xlarge-caching-executor
    description: publish docker images with a pre-* tag.
    steps:
      - run:
          command: |
            sudo mkdir -p /opt/cargo/
            sudo chown circleci /opt/cargo/
            sudo mkdir -p /opt/git/
            sudo chown circleci /opt/git/
          working_directory: ~/project
      - checkout:
          path: *working_directory
      - run:
          name: should pre build docker images (targeting a release branch)?
          command: |
            eval `.circleci/get_pr_info.sh -b`
            if  [[ ! "$TARGET_BRANCH" =~ "^release-[0-9|.]+$" ]] && [[ ! "$TARGET_BRANCH" =~ "^test-[0-9|.]+$" ]] ; then
              echo Targeting branch $TARGET_BRANCH will not publish docker images.
              circleci step halt
            fi
      - setup_docker_signing
      - run:
          name: pre-release docker images
          command: |
            BRANCH=${CIRCLE_BRANCH}
            success=0
            docker/build_push.sh -u -p -b ${BRANCH} -n client || success=-1
            docker/build_push.sh -u -p -b ${BRANCH} -n init || success=-1
            docker/build_push.sh -u -p -b ${BRANCH} -n faucet || success=-1
            docker/build_push.sh -u -p -b ${BRANCH} -n tools || success=-1
            docker/build_push.sh -u -p -b ${BRANCH} -n validator || success=-1
            docker/build_push.sh -u -p -b ${BRANCH} -n validator-tcb || success=-1
            docker/build_push.sh -u -p -b ${BRANCH} -n cluster-test || success=-1
            exit $success

  ######################################################################################################
  # Docker Builds:                                                                                     #
  ######################################################################################################
  docker-publish:
    working_directory: *working_directory
    executor: vm-xlarge-caching-executor
    description: publish docker images
    steps:
      - run:
          command: |
            sudo mkdir -p /opt/cargo/
            sudo chown circleci /opt/cargo/
            sudo mkdir -p /opt/git/
            sudo chown circleci /opt/git/
          working_directory: ~/project
      - checkout:
          path: *working_directory
      - setup_docker_signing
      - setup_aws
      - run:
          name: pull pre images (or build if not pullable) and push release docker images
          command: |
            set -x
            BRANCH=${CIRCLE_BRANCH}
            success=0
            docker/build_push.sh -u -b ${BRANCH} -n client || success=-1
            docker/build_push.sh -u -b ${BRANCH} -n init || success=-1
            docker/build_push.sh -u -b ${BRANCH} -n faucet || success=-1
            docker/build_push.sh -u -b ${BRANCH} -n tools || success=-1
            docker/build_push.sh -u -b ${BRANCH} -n validator || success=-1
            docker/build_push.sh -u -b ${BRANCH} -n validator-tcb || success=-1
            docker/build_push.sh -u -b ${BRANCH} -n cluster-test || success=-1
            exit $success
      - run:
          name: docker image pruning.
          command: |
            scripts/dockerhub_prune.sh -u "${DOCKERHUB_USERNAME}" -p "${DOCKERHUB_PASSWORD}" -x
      - run:
          name: push to novi ecr
          when: always
          command: |
            #push to novi ecr with standard names
            BRANCH=${CIRCLE_BRANCH}
            GIT_REV=$(git rev-parse --short=8 HEAD)
            aws ecr get-login-password --region ${AWS_REGION} | \
            docker login --username AWS --password-stdin "${AWS_ECR_ACCOUNT_URL}"
            docker/dockerhub_to_novi_ecr.sh -t ${BRANCH}_${GIT_REV} -r ${AWS_ECR_ACCOUNT_URL}

  ######################################################################################################################
  #  Code Coverage for unit tests (targets S3 html upload, codecov.io output, and slack with failed tests/compilations)
  ######################################################################################################################

  code_coverage:
    working_directory: *working_directory
    executor: vm-xlarge-executor
    description: Run code coverage
    environment:
      MESSAGE_PAYLOAD_FILE: "/tmp/message_payload"
    steps:
      - vm_build_setup
      - run:
          name: install lcov (let x install grcov)
          command: |
            if which lcov &>/dev/null; then
               echo "lcov is already installed"
            else
              sudo apt-get install lcov --no-install-recommends -y
            fi
      - restore_cache:
          name: restore daily latch cache file.
          key: code-coverage-daily
      - run:
          name: Halt job if already built code coverage today.
          command: |
            NOW=`date +%Y-%m-%d`
            LAST=`cat /home/circleci/lastbuild` || true
            if [[ "$LAST" == "$NOW" ]]; then
              echo Last build occured today, halting.
              circleci step halt
            else
              echo Last build occured $LAST, building.
              date +%Y-%m-%d > /home/circleci/lastbuild
            fi
      - save_cache:
          name: store updated daily latch file.
          key: code-coverage-daily-{{ epoch }}
          paths:
            - /home/circleci/lastbuild
      - aws-cli/configure:
          aws-access-key-id: AWS_ACCESS_KEY_ID
          aws-secret-access-key: AWS_SECRET_ACCESS_KEY
          aws-region: AWS_REGION
      - run:
          name: Setup code coverage output
          command: |
            echo "export CODECOV_OUTPUT=codecov" >> $BASH_ENV
      - run:
          name: Run code coverage
          command: |
            cargo xtest --html-cov-dir=$CODECOV_OUTPUT/grcovhtml/ --html-lcov-dir=$CODECOV_OUTPUT/lcovhtml/ --no-fail-fast -j 8 || true
          no_output_timeout: 20m
      - run:
          name: Upload result to codecov.io
          command: bash <(curl -s https://codecov.io/bash) -f $CODECOV_OUTPUT/lcovhtml/lcov.info -F unittest;
      - run:
          name: Push Coverage Reports to S3
          command: |
            set -x
            SUFFIX="$(date +"%Y-%m-%d")-$(git rev-parse --short=8 HEAD)"
            PREFIX="ci-artifacts.diem.com/coverage";
            #Push grcov
            aws s3 cp --recursive ${CODECOV_OUTPUT}/grcovhtml "s3://${PREFIX}/unit-coverage/${SUFFIX}/";
            aws s3 cp --recursive ${CODECOV_OUTPUT}/grcovhtml "s3://${PREFIX}/unit-coverage/latest/";
            echo "Grcov available in s3 https://${PREFIX}/unit-coverage/${SUFFIX}/index.html" >> ${MESSAGE_PAYLOAD_FILE}
            #Push lcov
            aws s3 cp --recursive ${CODECOV_OUTPUT}/lcovhtml "s3://${PREFIX}/lcov-unit-coverage/${SUFFIX}/";
            aws s3 cp --recursive ${CODECOV_OUTPUT}/lcovhtml "s3://${PREFIX}/lcov-unit-coverage/latest/";
            echo "lcov available in s3 https://${PREFIX}/lcov-unit-coverage/${SUFFIX}/index.html" >> ${MESSAGE_PAYLOAD_FILE}
      - send_message:
          payload_file: "${MESSAGE_PAYLOAD_FILE}"
          build_url: "${CIRCLE_BUILD_URL}#tests/containers/${CIRCLE_NODE_INDEX}"
          webhook: "${WEBHOOK_COVERAGE_INFO}"

workflows:
  ######################################################################################################################
  # Once a day when a change lands on master, rebuild the CI base image and code coverage.
  # Will build the CI base image when relevant files are changed vs on master, on either master or test branches.
  ######################################################################################################################
  latched-publish-workflow:
    jobs:
      - code_coverage:
          context: libra_ci
          filters:
            branches:
              only:
                - /^test-[\d|.]+$/
                - master
      - docker-ci-build:
          context: docker
          release: true
          target-image: circleci
          version: 2
          filters:
            branches:
              only:
                - /^test-[\d|.]+$/
                - master

  ######################################################################################################################
  # Will publish release images to dockerhub and aws when commits land on a release/testing branch.                    #
  # Will also push base images to novi aws ecr to prevent dockerhub api limit violations.                              #
  ######################################################################################################################
  release-dockerhub-publish:
    jobs:
      - docker-publish:
          context: docker
          filters:
            branches:
              only:
                - /^test-[\d|.]+$/
                - /^release-[\d|.]+$/
                - master
      - docker-update-base-images:
          context: docker
          filters:
            branches:
              only:
                - master

  ######################################################################################################################
  # Updates documentation when code is committed to master, and checks for breaking changes.
  ######################################################################################################################
  document-publish-workflow:
    jobs:
      - prefetch-crates:
          filters:
            branches:
              only: master
      - lint:
          requires:
            - prefetch-crates
      - check-breaking-change:
          requires:
            - prefetch-crates

  ######################################################################################################################
  # Used by bors to test prs on master's head before committing to master.                                             #
  # The "commit-workflow" must support auto and canary branchs...                                                      #
  # The "commit-workflow", and the  pull-request-workflow should be identical.                                         #
  ######################################################################################################################
  commit-workflow:
    jobs:
      - lint-docker:
          filters: *filter-only-auto-canary
      - prefetch-crates:
          filters: *filter-only-auto-canary
      - lint:
          requires:
            - prefetch-crates
      - build-dev:
          context: libra_ci
          requires:
            - prefetch-crates
      - run-e2e-test:
          context: libra_ci
          requires:
            - prefetch-crates
      - run-unit-test:
          context: libra_ci
          requires:
            - prefetch-crates
      - run-crypto-unit-test:
          context: libra_ci
          requires:
            - prefetch-crates
      - build-benchmark:
          context: libra_ci
          requires:
            - prefetch-crates
      - docker-ci-build:
          target-image: circleci
          filters: *filter-only-auto-canary
      - docker-ci-build:
          target-image: centos
          filters: *filter-only-auto-canary
      - docker-ci-build:
          #sccache fails to execute in alpine.
          target-image: alpine
          filters: *filter-only-auto-canary
      - docker-ci-build:
          target-image: arch
          filters: *filter-only-auto-canary
      - docker-pre-publish:
          context: docker
          filters:
            branches:
              only: auto

  pull-request-workflow:
    jobs:
      - lint-docker:
          filters: *filter-only-prs-dependabot
      - prefetch-crates:
          filters: *filter-only-prs-dependabot
      - lint:
          requires:
            - prefetch-crates
      - build-dev:
          requires:
            - prefetch-crates
      - run-e2e-test:
          requires:
            - prefetch-crates
      - run-unit-test:
          requires:
            - prefetch-crates
      - run-crypto-unit-test:
          requires:
            - prefetch-crates
      - build-benchmark:
          requires:
            - prefetch-crates
      - docker-ci-build:
          target-image: circleci
          filters: *filter-only-prs-dependabot
      - docker-ci-build:
          target-image: centos
          filters: *filter-only-prs-dependabot
      - docker-ci-build:
          #sccache fails to execute in alpine.
          target-image: alpine
          filters: *filter-only-prs-dependabot
      - docker-ci-build:
          target-image: arch
          filters: *filter-only-prs-dependabot

  scheduled-workflow:
    triggers:
      - schedule:
          cron: "14 14 * * *"
          filters:
            branches:
              only: master
    jobs:
      - audit

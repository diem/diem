apiVersion: batch/v1
kind: Job
metadata:
  name: {{ include "backup.fullname" . }}-restore-{{ randAlpha 4 | lower }}
  labels:
    {{- include "backup.labels" . | nindent 4 }}
    app.kubernetes.io/name: restore
spec:
  completions: 0
  template:
    metadata:
      labels:
        {{- include "backup.selectorLabels" . | nindent 8 }}
        app.kubernetes.io/name: restore
      annotations:
        seccomp.security.alpha.kubernetes.io/pod: runtime/default
    spec:
      restartPolicy: Never
      terminationGracePeriodSeconds: 0
      {{- with .Values.restore }}
      containers:
      - name: restore
        image: {{ .image.repo }}:{{ .image.tag | default $.Values.imageTag }}
        imagePullPolicy: {{ .image.pullPolicy }}
        resources:
          {{- toYaml .resources | nindent 10 }}
        command:
        - sh
        - -c
        - |-
          set -ex
          # cleanup diemdb
          if [ ! -f /opt/diem/data/restore-uid ] || [ "$(cat /opt/diem/data/restore-uid)" != "$CONTROLLER_UID" ]; then
              rm -rf /opt/diem/data/db
              echo "$CONTROLLER_UID" > /opt/diem/data/restore-uid
          fi
          # start restore process
          /usr/local/bin/db-restore --concurrent-downloads {{ .config.concurrent_downloads }}{{ range .config.trusted_waypoints }} --trust-waypoint {{ . }}{{ end }} --target-db-dir /opt/diem/data/db auto --metadata-cache-dir /tmp/diem-restore-metadata command-adapter --config /opt/diem/etc/{{ .config.location }}.toml
        env:
        - name: RUST_LOG
          value: "debug"
        - name: RUST_BACKTRACE
          value: "1"
        - name: STRUCT_LOG_TCP_ADDR
          value: {{ include "backup.loggingAddress" $ | quote }}
        {{- if (include "backup.pushGateway" $) }}
        - name: PUSH_METRICS_ENDPOINT
          value: "{{- include "backup.pushGateway" $ }}/metrics/job/{{- .jobName | default "db_restore" }}"
        {{- end }}
        - name: CONTROLLER_UID
          valueFrom:
            fieldRef:
              fieldPath: "metadata.labels['controller-uid']"
        {{- include "backup.backupEnvironment" (dict "config" .config "era" $.Values.chain.era) | nindent 8 }}
        volumeMounts:
        - name: backup-config
          mountPath: /opt/diem/etc
        - name: diem-data
          mountPath: /opt/diem/data
        - name: tmp
          mountPath: /tmp
        securityContext:
          readOnlyRootFilesystem: true
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
      securityContext:
        runAsNonRoot: true
        runAsUser: 6180
        runAsGroup: 6180
        fsGroup: 6180
      {{- with .nodeSelector }}
      nodeSelector:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- with .affinity }}
      affinity:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- with .tolerations }}
      tolerations:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- end }}
      volumes:
      - name: backup-config
        configMap:
          name: {{ include "backup.fullname" . }}-backup
      - name: tmp
        emptyDir: {}
      - name: diem-data
        persistentVolumeClaim:
          claimName: {{ include "backup.persistentVolumeClaim" . }}
      serviceAccountName: {{ include "backup.serviceAccount" . }}
      {{- if .Values.imagePullSecret }}
      imagePullSecrets:
      - name: {{.Values.imagePullSecret}}
      {{- end }}
